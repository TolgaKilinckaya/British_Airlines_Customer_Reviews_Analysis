{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "---\n",
    "\n",
    "## Web scraping and analysis\n",
    "\n",
    "This Jupyter notebook includes some code to get you started with web scraping. We will use a package called `BeautifulSoup` to collect the data from the web. Once you've collected your data and saved it into a local `.csv` file you should start with your analysis.\n",
    "\n",
    "### Scraping Review Data from Skytrax\n",
    "\n",
    "If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
    "\n",
    "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total reviews\n",
      "Scraping page 2\n",
      "   ---> 200 total reviews\n",
      "Scraping page 3\n",
      "   ---> 300 total reviews\n",
      "Scraping page 4\n",
      "   ---> 400 total reviews\n",
      "Scraping page 5\n",
      "   ---> 500 total reviews\n",
      "Scraping page 6\n",
      "   ---> 600 total reviews\n",
      "Scraping page 7\n",
      "   ---> 700 total reviews\n",
      "Scraping page 8\n",
      "   ---> 800 total reviews\n",
      "Scraping page 9\n",
      "   ---> 900 total reviews\n",
      "Scraping page 10\n",
      "   ---> 1000 total reviews\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 10\n",
    "page_size = 100\n",
    "\n",
    "reviews = []\n",
    "\n",
    "# for i in range(1, pages + 1):\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        reviews.append(para.get_text())\n",
    "    \n",
    "    print(f\"   ---> {len(reviews)} total reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅ Trip Verified |  My daughter and I were deni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified | Despite boarding being the u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Verified |  Flight cancelled, no crew! 9th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Verified |  The worst service ever, my bag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |  4/4 flights we booked this ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews\n",
       "0  ✅ Trip Verified |  My daughter and I were deni...\n",
       "1  ✅ Trip Verified | Despite boarding being the u...\n",
       "2  Not Verified |  Flight cancelled, no crew! 9th...\n",
       "3  Not Verified |  The worst service ever, my bag...\n",
       "4  ✅ Trip Verified |  4/4 flights we booked this ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"reviews\"] = reviews\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you have your dataset for this task! The loops above collected 1000 reviews by iterating through the paginated pages on the website. However, if you want to collect more data, try increasing the number of pages!\n",
    "\n",
    " The next thing that you should do is clean this data to remove any unnecessary text from each of the rows. For example, \"✅ Trip Verified\" can be removed from each row if it exists, as it's not relevant to what we want to investigate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Route Data from Skytrax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total routes\n",
      "Scraping page 2\n",
      "   ---> 200 total routes\n",
      "Scraping page 3\n",
      "   ---> 300 total routes\n",
      "Scraping page 4\n",
      "   ---> 400 total routes\n",
      "Scraping page 5\n",
      "   ---> 500 total routes\n",
      "Scraping page 6\n",
      "   ---> 600 total routes\n",
      "Scraping page 7\n",
      "   ---> 700 total routes\n",
      "Scraping page 8\n",
      "   ---> 800 total routes\n",
      "Scraping page 9\n",
      "   ---> 900 total routes\n",
      "Scraping page 10\n",
      "   ---> 1000 total routes\n"
     ]
    }
   ],
   "source": [
    "route_list = []\n",
    "\n",
    "# for i in range(1, pages + 1):\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Create a BeautifulSoup object\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # We find the 'route' information for each table\n",
    "    for review in soup.find_all('article', {'itemprop': 'review'}):\n",
    "        route_info = review.find('table', {'class': 'review-ratings'}).find('td', text='Route')\n",
    "        if route_info:\n",
    "            route_value = route_info.find_next_sibling('td').text\n",
    "        else:\n",
    "            route_value = np.nan  # If there is no 'route' information, we add NaN\n",
    "        route_list.append(route_value)\n",
    "    \n",
    "    print(f\"   ---> {len(route_list)} total routes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Rota</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅ Trip Verified |  My daughter and I were deni...</td>\n",
       "      <td>Madrid to Vancouver via London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified | Despite boarding being the u...</td>\n",
       "      <td>London to Santiago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Verified |  Flight cancelled, no crew! 9th...</td>\n",
       "      <td>London Heathrow to Faro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Verified |  The worst service ever, my bag...</td>\n",
       "      <td>Kuwait to Lisbon via London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |  4/4 flights we booked this ...</td>\n",
       "      <td>London to Munich</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  \\\n",
       "0  ✅ Trip Verified |  My daughter and I were deni...   \n",
       "1  ✅ Trip Verified | Despite boarding being the u...   \n",
       "2  Not Verified |  Flight cancelled, no crew! 9th...   \n",
       "3  Not Verified |  The worst service ever, my bag...   \n",
       "4  ✅ Trip Verified |  4/4 flights we booked this ...   \n",
       "\n",
       "                             Rota  \n",
       "0  Madrid to Vancouver via London  \n",
       "1              London to Santiago  \n",
       "2         London Heathrow to Faro  \n",
       "3     Kuwait to Lisbon via London  \n",
       "4                London to Munich  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We transform the data into a pandas DataFrame\n",
    "df[\"Rota\"] = route_list\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Seat Type Data from Skytrax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total seat type\n",
      "Scraping page 2\n",
      "   ---> 200 total seat type\n",
      "Scraping page 3\n",
      "   ---> 300 total seat type\n",
      "Scraping page 4\n",
      "   ---> 400 total seat type\n",
      "Scraping page 5\n",
      "   ---> 500 total seat type\n",
      "Scraping page 6\n",
      "   ---> 600 total seat type\n",
      "Scraping page 7\n",
      "   ---> 700 total seat type\n",
      "Scraping page 8\n",
      "   ---> 800 total seat type\n",
      "Scraping page 9\n",
      "   ---> 900 total seat type\n",
      "Scraping page 10\n",
      "   ---> 1000 total seat type\n"
     ]
    }
   ],
   "source": [
    "seat_list = []\n",
    "\n",
    "# for i in range(1, pages + 1):\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Create a BeautifulSoup object\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # For each table we find the 'seat' information\n",
    "    for review in soup.find_all('article', {'itemprop': 'review'}):\n",
    "        seat_info = review.find('table', {'class': 'review-ratings'}).find('td', text='Seat Type')\n",
    "        if seat_info:\n",
    "            seat_value = seat_info.find_next_sibling('td').text\n",
    "        else:\n",
    "            seat_value = np.nan  # If there is no 'seat' information, we add NaN\n",
    "        seat_list.append(seat_value)\n",
    "    \n",
    "    print(f\"   ---> {len(seat_list)} total seat type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Rota</th>\n",
       "      <th>Seat_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅ Trip Verified |  My daughter and I were deni...</td>\n",
       "      <td>Madrid to Vancouver via London</td>\n",
       "      <td>Business Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified | Despite boarding being the u...</td>\n",
       "      <td>London to Santiago</td>\n",
       "      <td>Business Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Verified |  Flight cancelled, no crew! 9th...</td>\n",
       "      <td>London Heathrow to Faro</td>\n",
       "      <td>Business Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Verified |  The worst service ever, my bag...</td>\n",
       "      <td>Kuwait to Lisbon via London</td>\n",
       "      <td>Economy Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |  4/4 flights we booked this ...</td>\n",
       "      <td>London to Munich</td>\n",
       "      <td>Economy Class</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  \\\n",
       "0  ✅ Trip Verified |  My daughter and I were deni...   \n",
       "1  ✅ Trip Verified | Despite boarding being the u...   \n",
       "2  Not Verified |  Flight cancelled, no crew! 9th...   \n",
       "3  Not Verified |  The worst service ever, my bag...   \n",
       "4  ✅ Trip Verified |  4/4 flights we booked this ...   \n",
       "\n",
       "                             Rota       Seat_Type  \n",
       "0  Madrid to Vancouver via London  Business Class  \n",
       "1              London to Santiago  Business Class  \n",
       "2         London Heathrow to Faro  Business Class  \n",
       "3     Kuwait to Lisbon via London   Economy Class  \n",
       "4                London to Munich   Economy Class  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We transform the data into a pandas DataFrame\n",
    "df[\"Seat_Type\"] = seat_list\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Numerical Datas from Skytrax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 700 total numerical values.\n",
      "Scraping page 2\n",
      "   ---> 1400 total numerical values.\n",
      "Scraping page 3\n",
      "   ---> 2100 total numerical values.\n",
      "Scraping page 4\n",
      "   ---> 2800 total numerical values.\n",
      "Scraping page 5\n",
      "   ---> 3500 total numerical values.\n",
      "Scraping page 6\n",
      "   ---> 4200 total numerical values.\n",
      "Scraping page 7\n",
      "   ---> 4900 total numerical values.\n",
      "Scraping page 8\n",
      "   ---> 5600 total numerical values.\n",
      "Scraping page 9\n",
      "   ---> 6300 total numerical values.\n",
      "Scraping page 10\n",
      "   ---> 7000 total numerical values.\n"
     ]
    }
   ],
   "source": [
    "seat_comfort_list = []\n",
    "cabin_staff_service_list = []\n",
    "food_and_beverages_list = []\n",
    "inflight_entertainment_list = []\n",
    "ground_service_list = []\n",
    "wifi_and_connectivity_list = []\n",
    "value_for_money_list = []\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(1, pages + 1):\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Create a BeautifulSoup object\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # For each table we find the 'Seat Comfort' information\n",
    "    for review in soup.find_all('article', {'itemprop': 'review'}):\n",
    "        seat_info = review.find('table', {'class': 'review-ratings'}).find('td', text='Seat Comfort')\n",
    "        if seat_info:\n",
    "            filled_stars = int(len(seat_info.find_next_sibling('td').find_all('span', {'class': 'fill'})))\n",
    "        else:\n",
    "            filled_stars = np.nan  # If there is no 'Seat Comfort' information, we add NaN\n",
    "        seat_comfort_list.append(filled_stars)\n",
    "\n",
    "    # For each table we find the 'Cabin Staff Service' information\n",
    "    for review in soup.find_all('article', {'itemprop': 'review'}):\n",
    "        cabin_staff_service_info = review.find('table', {'class': 'review-ratings'}).find('td', text='Cabin Staff Service')\n",
    "        if cabin_staff_service_info:\n",
    "            filled_stars = int(len(cabin_staff_service_info.find_next_sibling('td').find_all('span', {'class': 'fill'})))\n",
    "        else:\n",
    "            filled_stars = np.nan  # If there is no 'Cabin Staff Service' information, we add NaN\n",
    "        cabin_staff_service_list.append(filled_stars)\n",
    "    \n",
    "    # For each table we find the 'Food & Beverages' information\n",
    "    for review in soup.find_all('article', {'itemprop': 'review'}):\n",
    "        food_and_beverages_info = review.find('table', {'class': 'review-ratings'}).find('td', text='Food & Beverages')\n",
    "        if food_and_beverages_info:\n",
    "            filled_stars = int(len(food_and_beverages_info.find_next_sibling('td').find_all('span', {'class': 'fill'})))\n",
    "        else:\n",
    "            filled_stars = np.nan  # If there is no 'Food & Beverages' information, we add NaN\n",
    "        food_and_beverages_list.append(filled_stars)\n",
    "    \n",
    "    # For each table we find the 'Inflight Entertainment' information\n",
    "    for review in soup.find_all('article', {'itemprop': 'review'}):\n",
    "        inflight_entertainment_info = review.find('table', {'class': 'review-ratings'}).find('td', text='Inflight Entertainment')\n",
    "        if inflight_entertainment_info:\n",
    "            filled_stars = int(len(inflight_entertainment_info.find_next_sibling('td').find_all('span', {'class': 'fill'})))\n",
    "        else:\n",
    "            filled_stars = np.nan  # If there is no 'Inflight Entertainment' information, we add NaN\n",
    "        inflight_entertainment_list.append(filled_stars)\n",
    "    \n",
    "    # For each table we find the 'Ground Service' information\n",
    "    for review in soup.find_all('article', {'itemprop': 'review'}):\n",
    "        ground_service_info = review.find('table', {'class': 'review-ratings'}).find('td', text='Ground Service')\n",
    "        if ground_service_info:\n",
    "            filled_stars = int(len(ground_service_info.find_next_sibling('td').find_all('span', {'class': 'fill'})))\n",
    "        else:\n",
    "            filled_stars = np.nan  # If there is no 'Ground Service' information, we add NaN\n",
    "        ground_service_list.append(filled_stars)\n",
    "    \n",
    "    # For each table we find the 'Wifi & Connectivity' information\n",
    "    for review in soup.find_all('article', {'itemprop': 'review'}):\n",
    "        wifi_and_connectivity_info = review.find('table', {'class': 'review-ratings'}).find('td', text='Wifi & Connectivity')\n",
    "        if wifi_and_connectivity_info:\n",
    "            filled_stars = int(len(wifi_and_connectivity_info.find_next_sibling('td').find_all('span', {'class': 'fill'})))\n",
    "        else:\n",
    "            filled_stars = np.nan  # If there is no 'Wifi & Connectivity' information, we add NaN\n",
    "        wifi_and_connectivity_list.append(filled_stars)\n",
    "\n",
    "    # For each table we find the 'Value For Money information\n",
    "    for review in soup.find_all('article', {'itemprop': 'review'}):\n",
    "        value_for_money_info = review.find('table', {'class': 'review-ratings'}).find('td', text='Value For Money')\n",
    "        if value_for_money_info:\n",
    "            filled_stars = int(len(value_for_money_info.find_next_sibling('td').find_all('span', {'class': 'fill'})))\n",
    "        else:\n",
    "            filled_stars = np.nan  # If there is no 'Value For Money' information, we add NaN\n",
    "        value_for_money_list.append(filled_stars)\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"   ---> {len(seat_comfort_list+cabin_staff_service_list+food_and_beverages_list+inflight_entertainment_list+ground_service_list+wifi_and_connectivity_list+value_for_money_list)} total numerical values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Rota</th>\n",
       "      <th>Seat_Type</th>\n",
       "      <th>Seat_Comfort</th>\n",
       "      <th>Cabin_Staff_Service</th>\n",
       "      <th>Food_and_Beverages</th>\n",
       "      <th>Inflight_Entertainment</th>\n",
       "      <th>Ground_Service</th>\n",
       "      <th>Wifi_and_Connectivity</th>\n",
       "      <th>Value_for_Money</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅ Trip Verified |  My daughter and I were deni...</td>\n",
       "      <td>Madrid to Vancouver via London</td>\n",
       "      <td>Business Class</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified | Despite boarding being the u...</td>\n",
       "      <td>London to Santiago</td>\n",
       "      <td>Business Class</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Verified |  Flight cancelled, no crew! 9th...</td>\n",
       "      <td>London Heathrow to Faro</td>\n",
       "      <td>Business Class</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Verified |  The worst service ever, my bag...</td>\n",
       "      <td>Kuwait to Lisbon via London</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |  4/4 flights we booked this ...</td>\n",
       "      <td>London to Munich</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>✅ Trip Verified |  London to Lyon. The flight ...</td>\n",
       "      <td>London to Lyon</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>✅ Trip Verified |  London to Boston. I was sea...</td>\n",
       "      <td>London to Boston</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>✅ Trip Verified | Stockholm to London. Standar...</td>\n",
       "      <td>Stockholm to London</td>\n",
       "      <td>Business Class</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>✅ Trip Verified |  Amsterdam to London arrived...</td>\n",
       "      <td>Amsterdam to London</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>✅ Trip Verified |  Buenos Aires to London. We ...</td>\n",
       "      <td>Buenos Aires to London</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviews  \\\n",
       "0    ✅ Trip Verified |  My daughter and I were deni...   \n",
       "1    ✅ Trip Verified | Despite boarding being the u...   \n",
       "2    Not Verified |  Flight cancelled, no crew! 9th...   \n",
       "3    Not Verified |  The worst service ever, my bag...   \n",
       "4    ✅ Trip Verified |  4/4 flights we booked this ...   \n",
       "..                                                 ...   \n",
       "995  ✅ Trip Verified |  London to Lyon. The flight ...   \n",
       "996  ✅ Trip Verified |  London to Boston. I was sea...   \n",
       "997  ✅ Trip Verified | Stockholm to London. Standar...   \n",
       "998  ✅ Trip Verified |  Amsterdam to London arrived...   \n",
       "999  ✅ Trip Verified |  Buenos Aires to London. We ...   \n",
       "\n",
       "                               Rota       Seat_Type  Seat_Comfort  \\\n",
       "0    Madrid to Vancouver via London  Business Class           3.0   \n",
       "1                London to Santiago  Business Class           3.0   \n",
       "2           London Heathrow to Faro  Business Class           NaN   \n",
       "3       Kuwait to Lisbon via London   Economy Class           3.0   \n",
       "4                  London to Munich   Economy Class           1.0   \n",
       "..                              ...             ...           ...   \n",
       "995                  London to Lyon   Economy Class           2.0   \n",
       "996                London to Boston   Economy Class           3.0   \n",
       "997             Stockholm to London  Business Class           3.0   \n",
       "998             Amsterdam to London   Economy Class           4.0   \n",
       "999          Buenos Aires to London   Economy Class           1.0   \n",
       "\n",
       "     Cabin_Staff_Service  Food_and_Beverages  Inflight_Entertainment  \\\n",
       "0                    3.0                 NaN                     NaN   \n",
       "1                    5.0                 4.0                     NaN   \n",
       "2                    NaN                 NaN                     NaN   \n",
       "3                    1.0                 1.0                     1.0   \n",
       "4                    3.0                 1.0                     1.0   \n",
       "..                   ...                 ...                     ...   \n",
       "995                  1.0                 NaN                     NaN   \n",
       "996                  5.0                 4.0                     4.0   \n",
       "997                  5.0                 2.0                     NaN   \n",
       "998                  4.0                 NaN                     NaN   \n",
       "999                  2.0                 1.0                     1.0   \n",
       "\n",
       "     Ground_Service  Wifi_and_Connectivity  Value_for_Money  \n",
       "0               1.0                    NaN                1  \n",
       "1               2.0                    NaN                5  \n",
       "2               1.0                    NaN                1  \n",
       "3               3.0                    1.0                3  \n",
       "4               1.0                    1.0                1  \n",
       "..              ...                    ...              ...  \n",
       "995             1.0                    NaN                1  \n",
       "996             4.0                    1.0                5  \n",
       "997             1.0                    NaN                3  \n",
       "998             1.0                    NaN                3  \n",
       "999             1.0                    NaN                1  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We transform the data into a pandas DataFrame\n",
    "df[\"Seat_Comfort\"] = seat_comfort_list\n",
    "df[\"Cabin_Staff_Service\"] = cabin_staff_service_list\n",
    "df[\"Food_and_Beverages\"] = food_and_beverages_list\n",
    "df[\"Inflight_Entertainment\"] = inflight_entertainment_list\n",
    "df[\"Ground_Service\"] = ground_service_list\n",
    "df[\"Wifi_and_Connectivity\"] = wifi_and_connectivity_list\n",
    "df[\"Value_for_Money\"] = value_for_money_list\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"BA_DataSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42458545484000bf6c73f594349261ccb3c60320ad400363c8531ed8c5d8a2a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
